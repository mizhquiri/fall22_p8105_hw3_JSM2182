---
title: "Homework 3"
author: Jennifer Mizhquiri
output: github_document
---


```{r, echo = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
library(p8105.datasets)
data("ny_noaa")
data("instacart")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1


## Problem 2



```{r tidy_accel, echo = FALSE}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekend = if_else(day == "Saturday", 1, if_else(day == "Sunday", 1, 0))
  ) %>% 
  select(
    week, day_id, weekend, day, everything()
  ) %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "min_24h",
    values_to = "activity_count",
    names_prefix = "activity_") %>% 
  mutate(
    min_24h = as.numeric(min_24h),
    weekend = as.logical(weekend),
    day = as.factor(day),
    day = factor(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
  ) %>% 
  arrange(day_id, min_24h)

```

 
```{r}
head(accel_df)
```

The above is a snapshot of accelerometer data collected for a given individual diagnosed with CHD.There are `r nrow(accel_df)` observations. The variables in this dataset contain information on the sequential days (from days `r accel_df %>% pull(day_id) %>% min()` to `r accel_df %>% pull(day_id) %>% max()` and for each minute within each day). The accelerometer tracks activity which it quantifies as activity counts. 

_officehours_ how to fix axis, coding, because weekend should be a logical variable so i changed that but geom_path makes it look like something taht is not continuous per se... what would be the best way to mayube aartificially change the axis. using geom_path and weekend as a continuous variable would have also been interesting


```{r group_accel, eval = FALSE}

accel_df %>% 
  group_by(
    day) %>%
  mutate(
    total_activity_per_day = sum(activity_count, na.rm = TRUE)
  ) %>% 
  ggplot(
    aes(x = day_id, y = total_activity_per_day, color = weekend)) + geom_point() + geom_smooth() + 
  labs(
    x = "Days",
    y = "Total Activity Per Day",
    title = "CHF Patient Activity Level Varies by Weekend and Stable by Weekday",
    caption = "Data came from five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF)"
  )
```




```{r}
accel_df %>% 
  group_by(day, week) %>%
  summarize(
    total_activity_per_day = sum(activity_count, na.rm = TRUE)
  ) %>% #observations
  knitr::kable(digits = 2)
```


```{r}
accel_df %>% 
  group_by(day, week) %>%
  summarize(
    total_activity_per_day = sum(activity_count, na.rm = TRUE)
  ) %>% 
  pivot_wider(
    names_from = "day", 
    values_from = "total_activity_per_day") %>% 
  knitr::kable(digits = 2)
```

There are a few observable trend. As the weeks advanced, the patients activity level tended to remain stable on Mondays - Thursdays. From a given Friday to the next Friday (with one exception), activity levels overall seemed to increase. From a given Saturday to the following Saturday, it is possible that the patient may have neglected to wear the accelerometer due to the markedly decreased number of steps in the last two weeks relative to the precedeing three weeks. On Sundays, the activity levels also appeared to decrease although the accelerometer appeared to still be worn. Of course, given that the data collection is dependent on participant adherence to wearing an accelerometer 24 hours a day, this data is a best guess snapshot. To better inspect the missings a different visual format would be helpful. 

```{r}
accel_df %>% 
  group_by(min_24h, day) %>% 
  ggplot(aes(x = min_24h, y = activity_count, color = day)) + 
  geom_point(alpha = .3) +
  labs(
    x = "Minutes in a Day",
    y = "Activity Counts",
    title = "CHF Patient Activity Level Over the Course of a Day") + 
  scale_x_continuous(
    breaks = c(0, 200, 400, 600, 800, 1000, 1200, 1400), 
    limits = c(0, 1440) 
    )
```

The patient's activity level/score did not exceed 2500 per minute across most days. The patient was more active after 6AM overall, and tended to break the 2500 threshold particularly around 700 minutes, 10000 minutes, and 12000 minutes. These were more likely to occur on Sundays, Saturdays, Wednesdays, and Fridays. 


## Problem 3




```{r}
ny_noaa %>% 
  mutate(
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)) %>% 
  summary()
  
```


There are `r nrow(ny_noaa)` observations and `r ncol(ny_noaa)` variables. Specifically, there is weather data, such as the ID, the date, the precipitation, snow, snow and wind, max temperature and minimum temperature.In terms of missing data, snow depth (`snwd`) has the largest proportion of missing data relative to snow, precipitation, tmax, and tmin. There are 591786 missing values for snwd, 381221 missing values for snow, 145838 missing values for precipitation, 1134358 missing values for maximum temperature, and 1134420 missing values for minimum temperature.


```{r, echo = FALSE}
ny_noaa_tidy = 
  ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    year = as.integer(year),
    month = as.factor(month),
    day = as.integer(day),
    snow = as.numeric(snow),
    prcp = as.numeric(prcp),
    snwd = as.numeric(snwd),
    tmin = as.numeric(tmin),
    tmax = as.numeric(tmax),
    snow = snow * 10,
    snwd = snwd * 10,
    prcp = prcp * 100,
    tmax = tmax * 10, 
    tmin = tmin * 10) %>% 
  mutate(
    month = recode
      (month, 
        "01" = "January",
        "02" = "February", 
        "03" = "March", 
        "04" = "April", 
        "05" = "May", 
        "06" = "June", 
        "07" = "July", 
        "08" = "August", 
        "09" = "September", 
        "10" = "October", 
        "11" = "November", 
        "12" = "December"),
    month = factor(month, levels = c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"))
  )
  

```

For snowfall, what are the most commonly observed values? 
```{r}
ny_noaa_tidy %>% 
  count(
    snow) %>% 
  arrange(desc(n)) 

```
```{r}

ny_noaa_tidy %>% 
  group_by(snow) %>% 
  summarize(
     n_obs = n()) %>% 
  arrange(desc(n_obs))
```

  * The most commonly observed value of snow is 0cm (also: 0 mm)
  

Make a two-panel plot showing the average max temperature in January and in July in each station across years. Is there any observable / interpretable structure? Any outliers?
```{r}
ny_noaa_tidy %>%
    filter(
    month %in% c("January","July")) %>% 
  group_by(month, year, id) %>% 
  summarize(
    tmax_mean = mean(tmax, na.rm = TRUE)
  ) %>% 
  ggplot(aes(x = year, y = tmax_mean, group = id, color = tmax_mean)) +
  scale_x_continuous(
    breaks = c(1980, 1990, 2000, 2010),
    labels = c("1980", "1990", "2000", "2010")) +
  geom_line(alpha = 0.5) +
  labs(
    x = "Years",
    y = "Maximum Daily Temp (C)",
    title = "Line Graphs of daily temp extremes in June and July",
    caption = "Data came from the Rnooa package",
    linetype = "Max Temp (C)") + 

  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + 
  theme(legend.position = "right") + 
  facet_grid(. ~ month) 


```




Make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option); 
_office hours_ what is group = doing how do i differentiate the different Ids

```{r}
tmax_noaa_plot = 
  ny_noaa_tidy %>%
  group_by(year) %>% 
  ggplot(aes(x = year, y = tmax, group = year)) +
  geom_smooth(alpha = 0.5, na.rm = TRUE) + 
  scale_y_continuous(
    limits = c(100, 1500)
  ) 



tmin_noaa_plot =
  ny_noaa_tidy %>%
  group_by(year) %>% 
  ggplot(aes(x = year, y = tmin, group = year)) +
  geom_smooth(alpha = 0.5, na.rm = TRUE) +
  scale_y_continuous(
  limits = c(100, 1500)) 


tmax_noaa_plot + tmin_noaa_plot
      

```



and (ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year
  ggplot(aes(x = year, y = snow)) +
  geom_point(alpha = 0.5)

```{r}
ny_noaa_tidy %>% 
  group_by(year) %>% 
  mutate(
    snow = snow/10
  ) %>% 
  filter(
    between(
      snow,0,100),
    !snow %in% c(0,100)
    ) %>% 
  ggplot(aes(x = year, y = snow)) +
  geom_point(alpha = 0.5)
  

```


```{r}
ny_noaa_tidy %>% 
  group_by(year) %>% 
  mutate(
    snow = snow/10
  ) %>% 
  filter(
    between(
      snow,0,100),
    !(snow %in% c(0,100))
    ) %>% 
  ggplot(aes(x = year, y = snow, group = year)) +
  geom_boxplot(alpha = 0.5)
  
  
```

